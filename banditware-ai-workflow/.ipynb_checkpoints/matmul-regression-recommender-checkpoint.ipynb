{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fd243e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import sys\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import plotly\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import random\n",
    "from random import choices\n",
    "from string import ascii_lowercase, digits\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "from functools import partial\n",
    "from itertools import starmap\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import mlflow\n",
    "from mlflow import MlflowClient\n",
    "import mlflow.sklearn\n",
    "from mlflow.models import infer_signature\n",
    "from mlflow.models import Model\n",
    "from mlflow.data.pandas_dataset import PandasDataset\n",
    "\n",
    "# set mlflow traking uri\n",
    "mlflow.set_tracking_uri(uri=\"http://127.0.0.1:5000\")\n",
    "mlflow.enable_system_metrics_logging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d354c706",
   "metadata": {},
   "outputs": [],
   "source": [
    "this_dir = pathlib.Path()\n",
    "parent_dir = this_dir.resolve().parent\n",
    "data_dir = this_dir / \"matmul-data\"\n",
    "\n",
    "# create results directory, if not already existing\n",
    "cwd = os.getcwd()\n",
    "results_dir = os.path.join(cwd, r'matmul_results')\n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c01a4c",
   "metadata": {},
   "source": [
    "# Implement a simple recommender algorithm as linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993c2f87",
   "metadata": {},
   "source": [
    "# Eval and plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64b486f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL EVALUATION FUNCTIONS #\n",
    "\n",
    "def eval_metrics(actual, pred):\n",
    "        rmse = np.sqrt(mean_squared_error(actual, pred))\n",
    "        mae = mean_absolute_error(actual, pred)\n",
    "        r2 = r2_score(actual, pred)\n",
    "        return rmse, mae, r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edddd16b",
   "metadata": {},
   "source": [
    "# Data Prep"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4f849160",
   "metadata": {},
   "source": [
    "Matmul key:\n",
    "0 = (1, 8)\n",
    "1 = (2, 8)\n",
    "2 = (3, 8)\n",
    "3 = (4, 8)\n",
    "4 = (8, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762f22ff",
   "metadata": {},
   "source": [
    "hw_dict = {0 : (1,8), 1 : (2,8), 2 : (3,8) : 3 : (4,8), 4 : (8,8)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aac8cf13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "def data_prep(filename='train.csv', features=[\"size\", \"sparsity\", \"min\", \"max\"]):\n",
    "# Read and log the input data \n",
    "    data_filepath = data_dir / filename\n",
    "    data = pd.read_csv(data_filepath)\n",
    "    data_artifact = mlflow.data.from_pandas(data)  # log when run is started\n",
    "    \n",
    "    \n",
    "    ## DATA PREPROCESSING STEPS ##\n",
    "    # remove noisy features \n",
    "    feature_cols = data[features]\n",
    "    df = pd.concat([feature_cols, data['hardware']], axis=1)\n",
    "    \n",
    "    print(df.columns)\n",
    "    # Replace infty values with NaN\n",
    "    df.replace(['inf', np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "    # Impute NaN values with mean\n",
    "    imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "    sample_data = df.sample(frac=0.25).dropna()\n",
    "    imp_mean.fit(df)\n",
    "    df = pd.DataFrame(imp_mean.fit_transform(df), columns = df.columns)\n",
    "    \n",
    "    # Encode categorical features\n",
    "    for col_name in feature_cols.columns.tolist():\n",
    "        df[col_name] = df[col_name].astype('category').cat.codes\n",
    "    \n",
    "    return df, data_artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b0a06fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.stats import norm\n",
    "\n",
    "# # calculate the z* for a 90% confidence interval\n",
    "# confidence_level = 0.9\n",
    "# alpha = 1-confidence_level\n",
    "# z_star = norm.ppf(1 - alpha/2)\n",
    "\n",
    "# z_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c2de087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.stats import norm\n",
    "\n",
    "# z = -1\n",
    "# probability = norm.cdf(z)\n",
    "\n",
    "# 1 - probability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24addef5",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "876e4eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## DEFINE MODEL TRAINING FUNCTIONS##\n",
    "# TODO: Separate preprocessing and training/evaluation\n",
    "\n",
    "def train_recommender(train, test, experiment_id, seed=None, data_artifact=None, num_epochs=None, autologging=True):\n",
    "    mlflow.autolog()  # enable autologging\n",
    "    mlflow.sklearn.autolog()\n",
    "\n",
    "\n",
    "    # The target column\n",
    "    train_x = train.drop([\"hardware\"], axis=1)\n",
    "    test_x = test.drop([\"hardware\"], axis=1)\n",
    "    train_y = train[[\"hardware\"]]\n",
    "    test_y = test[[\"hardware\"]]\n",
    "    \n",
    "    # Normalize data\n",
    "    train_x_normalized_array, test_x_normalized_array = preprocessing.normalize(train_x, norm=\"l1\"), preprocessing.normalize(test_x, norm=\"l1\")\n",
    "    train_x, test_x = pd.DataFrame(data=train_x_normalized_array), pd.DataFrame(data=test_x_normalized_array)\n",
    "    \n",
    "    train_y_normalized_array, test_y_normalized_array = preprocessing.normalize(train_y, norm=\"l1\"), preprocessing.normalize(test_y, norm=\"l1\")\n",
    "    train_y, test_y = pd.DataFrame(data=train_y_normalized_array), pd.DataFrame(data=test_y_normalized_array)\n",
    "\n",
    "    \n",
    "    ## storage settings ##\n",
    "    model_type = 'LinearRegression'\n",
    "    now = datetime.datetime.now().strftime(\"%Y_%m_%d_%I%M%S%p\")\n",
    "    run_name = model_type + '_' + now\n",
    "    \n",
    "    \n",
    "    ## MLFLOW RUN ##\n",
    "    # useful for multiple runs\n",
    "    with mlflow.start_run(experiment_id=experiment_id, run_name=run_name, nested=True, log_system_metrics=True):\n",
    "        mlflow.sklearn.autolog()\n",
    "#         e_start = 1.0\n",
    "#         e_decay = 0.99\n",
    "        \n",
    "#         for epoch in range(0, num_epochs):\n",
    "#             # Decay epsilon\n",
    "#             epsilon = max(e_start * e_decay, 0)\n",
    "\n",
    "\n",
    "        # Execute recommender system\n",
    "        model = LinearRegression()\n",
    "        model.fit(train_x, train_y)\n",
    "\n",
    "\n",
    "\n",
    "        # Create model artifact directory\n",
    "        # cwd = os.getcwd()\n",
    "        artifacts_dir = os.path.join(results_dir, run_name)\n",
    "        if not os.path.exists(artifacts_dir):\n",
    "            os.makedirs(artifacts_dir)\n",
    "            \n",
    "            \n",
    "        # SET AND LOG PARAMETERS # \n",
    "        # (some model parameters will be autologged mlflow but not optuna)\n",
    "        mlflow.log_param(\"model_seed\", seed)\n",
    "        \n",
    "\n",
    "\n",
    "        ## IF AUTOLOGGING IS NOT ENABLED ##\n",
    "        if autologging==False:\n",
    "            \n",
    "            # Log and download artifacts locally --- file upload not yet supported in NDP JupyterHub\n",
    "            active_run = mlflow.active_run()\n",
    "            mlflow.artifacts.download_artifacts(run_id = active_run.info.run_id, dst_path=artifacts_dir)\n",
    "            mlflow.sklearn.log_model(sk_model=lr, input_example=test_x, artifact_path=artifacts_dir)\n",
    "        \n",
    "       \n",
    "    # log runtime\n",
    "\n",
    "\n",
    "    mlflow.end_run()   # END CURRENT RUN BEFORE STARTING NEW RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5eae01ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_model(experiment_id=None):\n",
    "    \n",
    "    # Opt. for now: get best run\n",
    "    best_run = mlflow.search_runs(\n",
    "        experiment_id, order_by=[\"metrics.eval_rmse\"], max_results=1\n",
    "    )\n",
    "    print(best_run.info)\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fc105b",
   "metadata": {},
   "source": [
    "# Run experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42fc186f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## EXPERIMENT FUNCTION ##\n",
    "def run_experiment(num_runs=10, train_func=train_recommender, num_samples=None, num_epochs=None, experiment_name=None):\n",
    "    \n",
    "    \n",
    "    # Generate experiment name\n",
    "    random_suffix = \"\".join(choices(ascii_lowercase, k=2)+choices(digits, k=3))\n",
    "    experiment_name = 'Recommender_'+random_suffix\n",
    "        \n",
    "    # create experiment (if not existing)\n",
    "    try:\n",
    "        mlflow.create_experiment(experiment_name)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    mlflow.set_experiment(experiment_name)\n",
    "\n",
    "    \n",
    "    # Get experiment ID\n",
    "    experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "    experiment_id = experiment.experiment_id\n",
    "    \n",
    "    # prep data\n",
    "#     df, data_artifact = data_prep(features=[\"area\", \"run_max_mem_rss_bytes\", \"sim_time\"])\n",
    "    train, train_artifact = data_prep(filename='train.csv')\n",
    "    test, test_artifact = data_prep(filename='test.csv')\n",
    "    \n",
    "    # Run experiments on train and test data\n",
    "    \n",
    "    for i in range(num_runs):\n",
    "        # Generate random seed\n",
    "        #warnings.filterwarnings(\"ignore\")\n",
    "        np_max_int = np.iinfo(np.int32).max\n",
    "        seed = np.random.randint(np_max_int)\n",
    "        np.random.seed(seed)\n",
    "        \n",
    "        # train recommender\n",
    "        train_recommender(train, test, experiment_id, seed=seed, num_epochs=10)\n",
    "        \n",
    "    \n",
    "    \n",
    "    return experiment_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87ce771f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['size', 'sparsity', 'min', 'max', 'hardware'], dtype='object')\n",
      "Index(['size', 'sparsity', 'min', 'max', 'hardware'], dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/08 17:23:08 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n",
      "2024/11/08 17:23:08 INFO mlflow.tracking.fluent: Autologging successfully enabled for statsmodels.\n",
      "2024/11/08 17:23:08 WARNING mlflow.system_metrics.system_metrics_monitor: Skip logging GPU metrics because creating `GPUMonitor` failed with error: `pynvml` is not installed, to log GPU metrics please run `pip install pynvml` to install it..\n",
      "2024/11/08 17:23:08 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n",
      "2024/11/08 17:23:08 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n",
      "2024/11/08 17:23:08 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute '_to_mlflow_entity'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/l3/6m8snshj0qj86xy5g4l3qkvw0000gp/T/ipykernel_27096/2518660784.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mexperiment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_runs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/l3/6m8snshj0qj86xy5g4l3qkvw0000gp/T/ipykernel_27096/3919894692.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(num_runs, train_func, num_samples, num_epochs, experiment_name)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp_max_int\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;31m# train recommender\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mtrain_recommender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/l3/6m8snshj0qj86xy5g4l3qkvw0000gp/T/ipykernel_27096/2048506123.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(train, test, experiment_id, seed, data_artifact, num_epochs, autologging)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m#             # Decay epsilon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m#             epsilon = max(e_start * e_decay, 0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;31m# Log data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mmlflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mmlflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.11/site-packages/mlflow/tracking/fluent.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(dataset, context, tags)\u001b[0m\n\u001b[1;32m    909\u001b[0m         \u001b[0mtags_to_log\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mInputTag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m         \u001b[0mtags_to_log\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mInputTag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMLFLOW_DATASET_CONTEXT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 913\u001b[0;31m     \u001b[0mdataset_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDatasetInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_to_mlflow_entity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtags_to_log\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m     \u001b[0mMlflowClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset_input\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5985\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5986\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5987\u001b[0m         ):\n\u001b[1;32m   5988\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5989\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute '_to_mlflow_entity'"
     ]
    }
   ],
   "source": [
    "experiment = run_experiment(num_runs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10e4f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_best_model(experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b521bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_runs = mlflow.search_runs(experiment, max_results=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4899c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = df_runs[\"metrics.training_root_mean_squared_error\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7084b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_runs.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5076b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_runs['duration'] = [(df_runs['end_time'][x] - df_runs['start_time'][x]).total_seconds() for x in range(0, df_runs.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeabd634",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_runs['metrics.training_root_mean_squared_error'].plot(kind='box', title='RMSE for linear regression model', grid=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63692b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_runs['duration'].plot(kind='box', title='Training duration for linear regression model', grid=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d260bfc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
