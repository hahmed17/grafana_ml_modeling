{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "096839e0-18ff-4087-9dac-7a3b18cdeda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import sys\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import plotly\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import random\n",
    "from random import choices\n",
    "from string import ascii_lowercase, digits\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "from functools import partial\n",
    "from itertools import starmap\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "import mlflow\n",
    "import optuna\n",
    "from mlflow import MlflowClient\n",
    "import mlflow.sklearn\n",
    "from mlflow.models import infer_signature\n",
    "from mlflow.models import Model\n",
    "from mlflow.data.pandas_dataset import PandasDataset\n",
    "\n",
    "# set mlflow traking uri\n",
    "mlflow.set_tracking_uri(uri=\"http://127.0.0.1:5000\")\n",
    "\n",
    "# override Optuna's default logging to ERROR only\n",
    "optuna.logging.set_verbosity(optuna.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "783dc60b-171b-4a69-8dce-59646e90e5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "this_dir = pathlib.Path()\n",
    "parent_dir = this_dir.resolve().parent\n",
    "data_dir = this_dir / \"data\"\n",
    "\n",
    "# create results directory, if not already existing\n",
    "cwd = os.getcwd()\n",
    "results_dir = os.path.join(cwd, r'results')\n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f9d65c-cc5e-47a5-9c9e-a892c86b6259",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a2b3ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL EVALUATION FUNCTIONS #\n",
    "\n",
    "def eval_metrics(actual, pred):\n",
    "        rmse = np.sqrt(mean_squared_error(actual, pred))\n",
    "        mae = mean_absolute_error(actual, pred)\n",
    "        r2 = r2_score(actual, pred)\n",
    "        return rmse, mae, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f173a914",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_model():\n",
    "    \n",
    "    # Opt. for now: get best run\n",
    "    best_run = mlflow.search_runs(\n",
    "        experiment_id, order_by=[\"metrics.rmse\"], max_results=1\n",
    "    )\n",
    "    print(best_run.info)\n",
    "    \n",
    "    return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0efa5054",
   "metadata": {},
   "outputs": [],
   "source": [
    "## VISUALIZATION FUNCTIONS ##\n",
    "def plot_residuals(y_test, y_pred, style=\"seaborn\", plot_size=(10, 8)):\n",
    "    \"\"\"Source: https://mlflow.org/docs/latest/traditional-ml/hyperparameter-tuning-with-child-runs/notebooks/logging-plots-in-mlflow.html\"\"\"\n",
    "    \n",
    "    residuals = y_test - y_pred\n",
    "\n",
    "    with plt.style.context(style=style):\n",
    "        fig, ax = plt.subplots(figsize=plot_size)\n",
    "        sns.residplot(\n",
    "            x=y_pred,\n",
    "            y=residuals,\n",
    "            lowess=True,\n",
    "            ax=ax,\n",
    "            line_kws={\"color\": \"red\", \"lw\": 1},\n",
    "        )\n",
    "\n",
    "        ax.axhline(y=0, color=\"black\", linestyle=\"--\")\n",
    "        ax.set_title(\"Residual Plot\", fontsize=14)\n",
    "        ax.set_xlabel(\"Predicted values\", fontsize=12)\n",
    "        ax.set_ylabel(\"Residuals\", fontsize=12)\n",
    "\n",
    "        for label in ax.get_xticklabels() + ax.get_yticklabels():\n",
    "            label.set_fontsize(10)\n",
    "\n",
    "        plt.tight_layout()\n",
    "\n",
    "        plt.close(fig)\n",
    "        return fig\n",
    "    \n",
    "    \n",
    "def plot_prediction_error(y_test, y_pred, style=\"seaborn\", plot_size=(10, 8)):\n",
    "    \"\"\"Source: https://mlflow.org/docs/latest/traditional-ml/hyperparameter-tuning-with-child-runs/notebooks/logging-plots-in-mlflow.html\"\"\"\n",
    "    \n",
    "    with plt.style.context(style=style):\n",
    "        fig, ax = plt.subplots(figsize=plot_size)\n",
    "        ax.scatter(y_pred, y_test - y_pred)\n",
    "        ax.axhline(y=0, color=\"red\", linestyle=\"--\")\n",
    "        ax.set_title(\"Prediction Error Plot\", fontsize=14)\n",
    "        ax.set_xlabel(\"Predicted Values\", fontsize=12)\n",
    "        ax.set_ylabel(\"Errors\", fontsize=12)\n",
    "        plt.tight_layout()\n",
    "    plt.close(fig)\n",
    "    return fig\n",
    "\n",
    "def plot_qq(y_test, y_pred, style=\"seaborn\", plot_size=(10, 8)):\n",
    "    \"\"\"Source: https://mlflow.org/docs/latest/traditional-ml/hyperparameter-tuning-with-child-runs/notebooks/logging-plots-in-mlflow.html\"\"\"\n",
    "    \n",
    "    residuals = y_test - y_pred\n",
    "    with plt.style.context(style=style):\n",
    "        fig, ax = plt.subplots(figsize=plot_size)\n",
    "        stats.probplot(residuals, dist=\"norm\", plot=ax)\n",
    "        ax.set_title(\"QQ Plot\", fontsize=14)\n",
    "        plt.tight_layout()\n",
    "    plt.close(fig)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62d29672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Future methods\n",
    "# Loading models: https://mlflow.org/docs/latest/python_api/mlflow.models.html#mlflow.models.Model.load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1376cfe-377d-4706-8b27-70347a39814e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## DEFINE MODEL TRAINING FUNCTIONS##\n",
    "# TODO: Separate preprocessing and training/evaluation\n",
    "\n",
    "def train_lr(target, experiment_id, in_alpha=0.5, in_l1_ratio=0.5):\n",
    "    mlflow.autolog()  # enable autologging\n",
    "    mlflow.sklearn.autolog()\n",
    "    \n",
    "    #warnings.filterwarnings(\"ignore\")\n",
    "    np_max_int = np.iinfo(np.int32).max\n",
    "    seed = np.random.randint(np_max_int)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # Read and log the input data \n",
    "    data_filepath = data_dir / 'training_data_w_timestep.csv'\n",
    "    data = pd.read_csv(data_filepath)\n",
    "    data_artifact = mlflow.data.from_pandas(data)  # log when run is started\n",
    "    \n",
    "    \n",
    "    ## DATA PREPROCESSING STEPS ##\n",
    "    \n",
    "    # remove noisy features: run_uuid, queue seconds, \n",
    "    data = data.drop(columns=['run_uuid', 'queue_seconds'])\n",
    "    \n",
    "    # Replace infty values with NaN\n",
    "    data.replace(['inf', np.inf, -np.inf], np.nan, inplace=True)\n",
    "    \n",
    "\n",
    "    # Impute NaN values with mean\n",
    "    imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "    sample_data = data.sample(frac=0.25).dropna()\n",
    "    imp_mean.fit(sample_data)\n",
    "    data = pd.DataFrame(imp_mean.fit_transform(data), columns = data.columns)\n",
    "    \n",
    "    # Split the data into training and testing (.75, .25) split\n",
    "    train, test = train_test_split(data)\n",
    "\n",
    "    # The target column (a function parameter) can be \"cpu_usage\" or \"mem_usage\"\n",
    "    if target == \"cpu_usage_total\":\n",
    "        train_x = train.drop([\"cpu_usage_total\"], axis=1)\n",
    "        test_x = test.drop([\"cpu_usage_total\"], axis=1)\n",
    "        train_y = train[[\"cpu_usage_total\"]]\n",
    "        test_y = test[[\"cpu_usage_total\"]]\n",
    "    elif target == \"mem_usage_total\":\n",
    "        train_x = train.drop([\"mem_usage_total\"], axis=1)\n",
    "        test_x = test.drop([\"mem_usage_total\"], axis=1)\n",
    "        train_y = train[[\"mem_usage_total\"]]\n",
    "        test_y = test[[\"mem_usage_total\"]]\n",
    "\n",
    "    \n",
    "    ## storage settings ##\n",
    "    model_type = 'Elasticnet'\n",
    "    now = datetime.datetime.now().strftime(\"%Y_%m_%d_%I%M%S%p\")\n",
    "    run_name = model_type + '_' + now\n",
    "    \n",
    "    \n",
    "    ## MLFLOW RUN ##\n",
    "    # useful for multiple runs\n",
    "    with mlflow.start_run(experiment_id=experiment_id, run_name=run_name, nested=True, log_system_metrics=True):\n",
    "        \n",
    "        # Log original input data\n",
    "        mlflow.log_input(data_artifact, \"input\")\n",
    "        \n",
    "        \n",
    "        # SET AND LOG PARAMETERS # \n",
    "        # (some model parameters will be autologged mlflow but not optuna)\n",
    "    \n",
    "        # Set default values if no alpha is provided\n",
    "        if float(in_alpha) is not None:\n",
    "            alpha = float(in_alpha)\n",
    "\n",
    "\n",
    "        # Set default values if no l1_ratio is provided\n",
    "        if float(in_l1_ratio) is not None:\n",
    "            l1_ratio = float(in_l1_ratio)\n",
    "\n",
    "        # Log pre-defined seed\n",
    "        mlflow.log_param(\"seed\", seed)  \n",
    "        \n",
    "        \n",
    "    \n",
    "        # Execute ElasticNet\n",
    "        lr = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, random_state=seed, fit_intercept=False)\n",
    "        lr.fit(train_x, train_y)\n",
    "    \n",
    "        \n",
    "        # Evaluate Metrics\n",
    "        pred_y = lr.predict(test_x)\n",
    "        (rmse, mae, r2) = eval_metrics(test_y, pred_y)\n",
    "    \n",
    "        # Print metrics\n",
    "        # print(\"Elasticnet model (alpha=%f, l1_ratio=%f):\" % (alpha, l1_ratio))\n",
    "        # print(\"  RMSE: %s\" % rmse)\n",
    "        # print(\"  MAE: %s\" % mae)\n",
    "        # print(\"  R2: %s\" % r2)\n",
    "\n",
    "        if test_y.shape != pred_y.shape:\n",
    "            test_y_dimensions = test_y.shape[0]\n",
    "            pred_y = pred_y.reshape(test_y_dimensions,1)\n",
    "            \n",
    "        \n",
    "        # Visualize and log plots\n",
    "        fig_residuals = plot_residuals(test_y, pred_y)\n",
    "        fig_error = plot_prediction_error(test_y, pred_y)\n",
    "        \n",
    "        mlflow.log_figure(fig_residuals, \"residuals_plot.png\")\n",
    "        mlflow.log_figure(fig_error, \"error_plot.png\")\n",
    "\n",
    "        \n",
    "        # Create model artifact directory\n",
    "        cwd = os.getcwd()\n",
    "        artifacts_dir = os.path.join(cwd, run_name)\n",
    "        if not os.path.exists(artifacts_dir):\n",
    "            os.makedirs(artifacts_dir)\n",
    "            \n",
    "            \n",
    "            \n",
    "         ## IF AUTOLOGGING IS NOT ENABLED ##\n",
    "        \n",
    "        # Log training data --- only if autologging not on\n",
    "        # train_dataset = mlflow.data.from_pandas(train, targets=target, source=\"data.csv\")\n",
    "        # mlflow.log_input(train_dataset, context=\"training\")\n",
    "        \n",
    "        # # Log parameters --- only if autologging is not on\n",
    "        # mlflow.log_param(\"alpha\", alpha)\n",
    "        # mlflow.log_param(\"l1_ratio\", l1_ratio)\n",
    "\n",
    "        # # Log metrics\n",
    "        # mlflow.log_metric(\"rmse\", rmse)\n",
    "        # mlflow.log_metric(\"r2\", r2)\n",
    "        # mlflow.log_metric(\"mae\", mae)\n",
    "        \n",
    "        # Log and download artifacts locally --- file upload not supported in NDP JupyterHub\n",
    "        # active_run = mlflow.active_run()\n",
    "        # mlflow.artifacts.download_artifacts(run_id = active_run.info.run_id, dst_path=artifacts_dir)\n",
    "        # mlflow.sklearn.log_model(sk_model=lr, input_example=test_x, artifact_path=artifacts_dir)\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "    mlflow.end_run()   # END CURRENT RUN BEFORE STARTING NEW RUN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e268b7-c483-411e-84a6-b2bd99dca77b",
   "metadata": {},
   "source": [
    "# Run experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68ef267a-a206-40fd-8306-581db773e073",
   "metadata": {},
   "outputs": [],
   "source": [
    "## EXPERIMENT FUNCTION ##\n",
    "def run_experiment(target=\"mem_usage_total\", num_runs=1, experiment_name=None, train_func=train_lr):\n",
    "    \n",
    "    \n",
    "    # Generate experiment name\n",
    "    if experiment_name is None:\n",
    "        random_suffix = \"\".join(choices(ascii_lowercase, k=2)+choices(digits, k=3))\n",
    "        if target == \"mem_usage_total\":\n",
    "            experiment_name = 'bp3d_mem_linreg_'+random_suffix\n",
    "        elif target == \"cpu_usage_total\":\n",
    "            experiment_name = 'bp3d_cpu_linreg_'+random_suffix\n",
    "\n",
    "    \n",
    "    # create experiment (if not existing)\n",
    "    try:\n",
    "        mlflow.create_experiment(experiment_name)\n",
    "    except:\n",
    "        pass\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "\n",
    "    \n",
    "    # Get experiment ID\n",
    "    experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "    experiment_id = experiment.experiment_id\n",
    "    \n",
    "    \n",
    "    for i in range(num_runs):\n",
    "        train_func(target, experiment_id)\n",
    "        \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2426c02-805c-49e1-afa9-eac6adf7091d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/07/30 10:48:08 INFO mlflow.tracking.fluent: Autologging successfully enabled for statsmodels.\n",
      "2024/07/30 10:48:09 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n",
      "2024/07/30 10:48:09 WARNING mlflow.system_metrics.system_metrics_monitor: Skip logging GPU metrics because creating `GPUMonitor` failed with error: `pynvml` is not installed, to log GPU metrics please run `pip install pynvml` to install it..\n",
      "2024/07/30 10:48:09 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n",
      "/Users/Hena/anaconda3/lib/python3.11/site-packages/mlflow/types/utils.py:393: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "/Users/Hena/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.039e+22, tolerance: 5.107e+19\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "2024/07/30 10:48:12 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/Users/Hena/anaconda3/lib/python3.11/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\"\n",
      "2024/07/30 10:48:13 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n",
      "2024/07/30 10:48:13 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n"
     ]
    }
   ],
   "source": [
    "run_experiment(target=\"mem_usage_total\", num_runs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c31eb4eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/07/30 10:48:13 INFO mlflow.tracking.fluent: Autologging successfully enabled for statsmodels.\n",
      "2024/07/30 10:48:13 WARNING mlflow.system_metrics.system_metrics_monitor: Skip logging GPU metrics because creating `GPUMonitor` failed with error: `pynvml` is not installed, to log GPU metrics please run `pip install pynvml` to install it..\n",
      "2024/07/30 10:48:13 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n",
      "/Users/Hena/anaconda3/lib/python3.11/site-packages/mlflow/types/utils.py:393: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "/Users/Hena/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.174e+11, tolerance: 5.777e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "2024/07/30 10:48:15 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n",
      "2024/07/30 10:48:15 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n"
     ]
    }
   ],
   "source": [
    "run_experiment(target=\"cpu_usage_total\", num_runs=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
