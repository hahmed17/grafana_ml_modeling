{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fd243e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import sys\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import plotly\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import random\n",
    "from random import choices\n",
    "from string import ascii_lowercase, digits\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "from functools import partial\n",
    "from itertools import starmap\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "import mlflow\n",
    "from mlflow import MlflowClient\n",
    "import mlflow.sklearn\n",
    "from mlflow.models import infer_signature\n",
    "from mlflow.models import Model\n",
    "from mlflow.data.pandas_dataset import PandasDataset\n",
    "\n",
    "# set mlflow traking uri\n",
    "mlflow.set_tracking_uri(uri=\"http://127.0.0.1:5000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d354c706",
   "metadata": {},
   "outputs": [],
   "source": [
    "this_dir = pathlib.Path()\n",
    "parent_dir = this_dir.resolve().parent\n",
    "data_dir = this_dir / \"data\"\n",
    "\n",
    "# create results directory, if not already existing\n",
    "cwd = os.getcwd()\n",
    "results_dir = os.path.join(cwd, r'baseline_results')\n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c01a4c",
   "metadata": {},
   "source": [
    "# Implement a simple recommender algorithm as linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a236d6c7",
   "metadata": {},
   "source": [
    "USING THE EXISTING FUNCTIONS, modify the existing train function to train a linear regression RECOMMENDER MODEL, then train/test the RECOMMENDER MODEL using the same data.\n",
    "\n",
    "Resource: https://medium.com/intro-to-artificial-intelligence/recommendation-engine-algorithm-collaborative-filtering-d1c837eaadfb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993c2f87",
   "metadata": {},
   "source": [
    "# Eval and plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64b486f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL EVALUATION FUNCTIONS #\n",
    "\n",
    "def eval_metrics(actual, pred):\n",
    "        rmse = np.sqrt(mean_squared_error(actual, pred))\n",
    "        mae = mean_absolute_error(actual, pred)\n",
    "        r2 = r2_score(actual, pred)\n",
    "        return rmse, mae, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cb5a712",
   "metadata": {},
   "outputs": [],
   "source": [
    "## VISUALIZATION FUNCTIONS ##\n",
    "def plot_residuals(y_test, y_pred, style=\"seaborn\", plot_size=(10, 8)):\n",
    "    \"\"\"Source: https://mlflow.org/docs/latest/traditional-ml/hyperparameter-tuning-with-child-runs/notebooks/logging-plots-in-mlflow.html\"\"\"\n",
    "    \n",
    "    residuals = y_test - y_pred\n",
    "\n",
    "    with plt.style.context(style=style):\n",
    "        fig, ax = plt.subplots(figsize=plot_size)\n",
    "        sns.residplot(\n",
    "            x=y_pred,\n",
    "            y=residuals,\n",
    "            lowess=True,\n",
    "            ax=ax,\n",
    "            line_kws={\"color\": \"red\", \"lw\": 1},\n",
    "        )\n",
    "\n",
    "        ax.axhline(y=0, color=\"black\", linestyle=\"--\")\n",
    "        ax.set_title(\"Residual Plot\", fontsize=14)\n",
    "        ax.set_xlabel(\"Predicted values\", fontsize=12)\n",
    "        ax.set_ylabel(\"Residuals\", fontsize=12)\n",
    "\n",
    "        for label in ax.get_xticklabels() + ax.get_yticklabels():\n",
    "            label.set_fontsize(10)\n",
    "\n",
    "        plt.tight_layout()\n",
    "\n",
    "        plt.close(fig)\n",
    "        return fig\n",
    "    \n",
    "    \n",
    "def plot_prediction_error(y_test, y_pred, style=\"seaborn\", plot_size=(10, 8)):\n",
    "    \"\"\"Source: https://mlflow.org/docs/latest/traditional-ml/hyperparameter-tuning-with-child-runs/notebooks/logging-plots-in-mlflow.html\"\"\"\n",
    "    \n",
    "    with plt.style.context(style=style):\n",
    "        fig, ax = plt.subplots(figsize=plot_size)\n",
    "        ax.scatter(y_pred, y_test - y_pred)\n",
    "        ax.axhline(y=0, color=\"red\", linestyle=\"--\")\n",
    "        ax.set_title(\"Prediction Error Plot\", fontsize=14)\n",
    "        ax.set_xlabel(\"Predicted Values\", fontsize=12)\n",
    "        ax.set_ylabel(\"Errors\", fontsize=12)\n",
    "        plt.tight_layout()\n",
    "    plt.close(fig)\n",
    "    return fig\n",
    "\n",
    "def plot_qq(y_test, y_pred, style=\"seaborn\", plot_size=(10, 8)):\n",
    "    \"\"\"Source: https://mlflow.org/docs/latest/traditional-ml/hyperparameter-tuning-with-child-runs/notebooks/logging-plots-in-mlflow.html\"\"\"\n",
    "    \n",
    "    residuals = y_test - y_pred\n",
    "    with plt.style.context(style=style):\n",
    "        fig, ax = plt.subplots(figsize=plot_size)\n",
    "        stats.probplot(residuals, dist=\"norm\", plot=ax)\n",
    "        ax.set_title(\"QQ Plot\", fontsize=14)\n",
    "        plt.tight_layout()\n",
    "    plt.close(fig)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edddd16b",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aac8cf13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "def data_prep(filename='training_data_cumulative.csv', autologging=True):\n",
    "# Read and log the input data \n",
    "    data_filepath = data_dir / filename\n",
    "    data = pd.read_csv(data_filepath)\n",
    "    data_artifact = mlflow.data.from_pandas(data)  # log when run is started\n",
    "    \n",
    "    \n",
    "    ## DATA PREPROCESSING STEPS ##\n",
    "    \n",
    "    # create target column\n",
    "    data[\"hardware_unencoded\"] = list(zip(data['# of cores'], data['memory (gb)']))\n",
    "    data['hardware_as_strings'] = data['hardware_unencoded'].apply(lambda x: ', '.join(map(str, x)))\n",
    "    \n",
    "    # encode targets\n",
    "    label_encoder = LabelEncoder()\n",
    "    data['hardware'] = label_encoder.fit_transform(data['hardware_as_strings'])\n",
    "\n",
    "    \n",
    "    # remove noisy features \n",
    "    feature_cols = data[[\"area\", \"wind_speed\", \"wind_direction\", \"canopy_moisture\", \"surface_moisture\"]]\n",
    "    df = pd.concat([feature_cols, data['hardware']], axis=1)\n",
    "    \n",
    "    print(df.columns)\n",
    "    # Replace infty values with NaN\n",
    "    df.replace(['inf', np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "    # Impute NaN values with mean\n",
    "    imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "    sample_data = df.sample(frac=0.25).dropna()\n",
    "    imp_mean.fit(df)\n",
    "    df = pd.DataFrame(imp_mean.fit_transform(df), columns = df.columns)\n",
    "    \n",
    "    # Encode categorical features\n",
    "    for col_name in feature_cols.columns.tolist():\n",
    "        df[col_name] = df[col_name].astype('category').cat.codes\n",
    "    \n",
    "    # Split the data into training and testing (.75, .25) split\n",
    "    train, test = train_test_split(df)\n",
    "    \n",
    "    if autologging==False:\n",
    "        # Log training data --- only if autologging not on\n",
    "        train_dataset = mlflow.data.from_pandas(train, targets=target, source=\"data.csv\")\n",
    "        mlflow.log_input(train_dataset, context=\"training\")\n",
    "    \n",
    "    return train, test, data_artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "876e4eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## DEFINE MODEL TRAINING FUNCTIONS##\n",
    "# TODO: Separate preprocessing and training/evaluation\n",
    "\n",
    "def train_recommender(train, test, data_artifact, experiment_id, in_alpha=0.5, in_l1_ratio=0.5, autologging=True):\n",
    "    mlflow.autolog()  # enable autologging\n",
    "    mlflow.sklearn.autolog()\n",
    "    \n",
    "    #warnings.filterwarnings(\"ignore\")\n",
    "    np_max_int = np.iinfo(np.int32).max\n",
    "    seed = np.random.randint(np_max_int)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "\n",
    "    # The target column (a function parameter) can be \"cpu_usage\" or \"mem_usage\"\n",
    "    train_x = train.drop([\"hardware\"], axis=1)\n",
    "    test_x = test.drop([\"hardware\"], axis=1)\n",
    "    train_y = train[[\"hardware\"]]\n",
    "    test_y = test[[\"hardware\"]]\n",
    "\n",
    "    \n",
    "    ## storage settings ##\n",
    "    model_type = 'LinearRegression'\n",
    "    now = datetime.datetime.now().strftime(\"%Y_%m_%d_%I%M%S%p\")\n",
    "    run_name = model_type + '_' + now\n",
    "    \n",
    "    \n",
    "    ## MLFLOW RUN ##\n",
    "    # useful for multiple runs\n",
    "    with mlflow.start_run(experiment_id=experiment_id, run_name=run_name, nested=True, log_system_metrics=True):\n",
    "        \n",
    "        # Log original input data\n",
    "        mlflow.log_input(data_artifact, \"input\")\n",
    "        \n",
    "        \n",
    "        # SET AND LOG PARAMETERS # \n",
    "        # (some model parameters will be autologged mlflow but not optuna)\n",
    "    \n",
    "        # Set default values if no alpha is provided\n",
    "        if float(in_alpha) is not None:\n",
    "            alpha = float(in_alpha)\n",
    "\n",
    "\n",
    "        # Set default values if no l1_ratio is provided\n",
    "        if float(in_l1_ratio) is not None:\n",
    "            l1_ratio = float(in_l1_ratio)\n",
    "\n",
    "        # Log pre-defined seed\n",
    "        mlflow.log_param(\"seed\", seed)  \n",
    "        \n",
    "        \n",
    "    \n",
    "        # Execute recommender system\n",
    "        model = LinearRegression()\n",
    "        model.fit(train_x, train_y)\n",
    "    \n",
    "        \n",
    "        # Evaluate Metrics\n",
    "        pred_y = model.predict(test_x)\n",
    "        (rmse, mae, r2) = eval_metrics(test_y, pred_y)\n",
    "    \n",
    "        # Print metrics\n",
    "        # print(\"LinearRegression model (alpha=%f, l1_ratio=%f):\" % (alpha, l1_ratio))\n",
    "        # print(\"  RMSE: %s\" % rmse)\n",
    "        # print(\"  MAE: %s\" % mae)\n",
    "        # print(\"  R2: %s\" % r2)\n",
    "\n",
    "        if test_y.shape != pred_y.shape:\n",
    "            test_y_dimensions = test_y.shape[0]\n",
    "            pred_y = pred_y.reshape(test_y_dimensions,1)\n",
    "            \n",
    "        \n",
    "        # Visualize and log plots\n",
    "        fig_residuals = plot_residuals(test_y, pred_y)\n",
    "        fig_error = plot_prediction_error(test_y, pred_y)\n",
    "        \n",
    "        mlflow.log_figure(fig_residuals, \"residuals_plot.png\")\n",
    "        mlflow.log_figure(fig_error, \"error_plot.png\")\n",
    "\n",
    "        \n",
    "        # Create model artifact directory\n",
    "        cwd = os.getcwd()\n",
    "        artifacts_dir = os.path.join(cwd, run_name)\n",
    "        if not os.path.exists(artifacts_dir):\n",
    "            os.makedirs(artifacts_dir)\n",
    "            \n",
    "            \n",
    "            \n",
    "         ## IF AUTOLOGGING IS NOT ENABLED ##\n",
    "        if autologging==False:\n",
    "            \n",
    "            # # Log parameters --- only if autologging is not on\n",
    "            mlflow.log_param(\"alpha\", alpha)\n",
    "            mlflow.log_param(\"l1_ratio\", l1_ratio)\n",
    "\n",
    "            # # Log metrics\n",
    "            mlflow.log_metric(\"rmse\", rmse)\n",
    "            mlflow.log_metric(\"r2\", r2)\n",
    "            mlflow.log_metric(\"mae\", mae)\n",
    "\n",
    "            # Log and download artifacts locally --- file upload not yet supported in NDP JupyterHub\n",
    "            active_run = mlflow.active_run()\n",
    "            mlflow.artifacts.download_artifacts(run_id = active_run.info.run_id, dst_path=artifacts_dir)\n",
    "            mlflow.sklearn.log_model(sk_model=lr, input_example=test_x, artifact_path=artifacts_dir)\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "    mlflow.end_run()   # END CURRENT RUN BEFORE STARTING NEW RUN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fc105b",
   "metadata": {},
   "source": [
    "# Run experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42fc186f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## EXPERIMENT FUNCTION ##\n",
    "def run_experiment(num_runs=1, experiment_name=None, train_func=train_recommender):\n",
    "    \n",
    "    \n",
    "    # Generate experiment name\n",
    "    random_suffix = \"\".join(choices(ascii_lowercase, k=2)+choices(digits, k=3))\n",
    "    experiment_name = 'Recommender'+random_suffix\n",
    "        \n",
    "    # create experiment (if not existing)\n",
    "    try:\n",
    "        mlflow.create_experiment(experiment_name)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    mlflow.set_experiment(experiment_name)\n",
    "\n",
    "    \n",
    "    # Get experiment ID\n",
    "    experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "    experiment_id = experiment.experiment_id\n",
    "    \n",
    "    # Generate train and test data\n",
    "    train, test, data_artifact = data_prep()\n",
    "    \n",
    "    # Run experiments on train and test data\n",
    "    for i in range(num_runs):\n",
    "        train_func(train, test, data_artifact, experiment_id)\n",
    "        \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87ce771f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/11 09:25:59 INFO mlflow.tracking.fluent: Autologging successfully enabled for statsmodels.\n",
      "2024/10/11 09:26:00 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['area', 'wind_speed', 'wind_direction', 'canopy_moisture',\n",
      "       'surface_moisture', 'hardware'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/11 09:26:00 WARNING mlflow.system_metrics.system_metrics_monitor: Skip logging GPU metrics because creating `GPUMonitor` failed with error: `pynvml` is not installed, to log GPU metrics please run `pip install pynvml` to install it..\n",
      "2024/10/11 09:26:00 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n",
      "2024/10/11 09:26:00 WARNING mlflow.data.pandas_dataset: Failed to infer schema for Pandas dataset. Exception: Failed to infer schema for pandas.Series 0       (2, 16)\n",
      "1       (2, 16)\n",
      "2       (2, 16)\n",
      "3       (2, 16)\n",
      "4       (2, 16)\n",
      "         ...   \n",
      "1369    (4, 16)\n",
      "1370    (4, 16)\n",
      "1371    (4, 16)\n",
      "1372    (4, 16)\n",
      "1373    (4, 16)\n",
      "Name: hardware_unencoded, Length: 1374, dtype: object. Error: Data (2, 16) is not one of the supported DataType\n",
      "2024/10/11 09:26:00 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/Users/Hena/anaconda3/lib/python3.11/site-packages/mlflow/types/utils.py:393: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2024/10/11 09:26:00 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/Users/Hena/anaconda3/lib/python3.11/site-packages/mlflow/types/utils.py:393: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2024/10/11 09:26:01 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/Users/Hena/anaconda3/lib/python3.11/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\"\n",
      "2024/10/11 09:26:01 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/Users/Hena/anaconda3/lib/python3.11/site-packages/mlflow/types/utils.py:393: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2024/10/11 09:26:02 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n",
      "2024/10/11 09:26:02 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n"
     ]
    }
   ],
   "source": [
    "run_experiment(num_runs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10e4f73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
